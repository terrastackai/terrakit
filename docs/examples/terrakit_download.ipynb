{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf11c7a",
   "metadata": {},
   "source": [
    "<!-- \n",
    " Â© Copyright IBM Corporation 2025\n",
    " SPDX-License-Identifier: Apache-2.0\n",
    " -->\n",
    "\n",
    "# TerraKit: Easy geospatial data search and query\n",
    "\n",
    "TerraKit Data Connectors can be used outside the TerraKit Pipeline. This notebook will guide you through using TerraKit Data Connectors to download data from different data collections.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Install TerraKit</b> For instructions on how to install TerraKit, take a look at the <a href=\"https://terrastackai.github.io/terrakit/\">Welcome</a> page.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from terrakit import DataConnector\n",
    "from terrakit.download.transformations.impute_nans_xarray import impute_nans_xarray\n",
    "from terrakit.download.transformations.scale_data_xarray import scale_data_xarray\n",
    "from terrakit.download.geodata_utils import save_data_array_to_file\n",
    "\n",
    "# To be able to query using a data connector, we will import api credentials from .env\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18078932",
   "metadata": {},
   "source": [
    "First, we create a DataConnector instance for the connector we wish to use.  You can list the available collections for that connector.\n",
    "\n",
    "Currently, you can select from:\n",
    "*  `sentinelhub`\n",
    "*  `sentinel_aws`\n",
    "*  `nasa_earthdata`\n",
    "*  `IBMResearchSTAC`\n",
    "*  `TheWeatherCompany`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90626647",
   "metadata": {},
   "source": [
    "### Sentinel-2-l2a from Sentinel AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f17643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connector = \"sentinel_aws\"\n",
    "dc = DataConnector(connector_type=data_connector)\n",
    "dc.connector.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c6c796",
   "metadata": {},
   "source": [
    "Now we can search for data.  To do so we select the collection and specify our bounding box and time range.\n",
    "\n",
    "The `find_data()` function will search for data and return both a list of unique dates where data is available, but also the raw results from the search.  In the case of a STAC catalogue, the results will be the STAC entries, for another connector, it will be the item details which are returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [34.671440, -0.090887, 34.706448, -0.087678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05876bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"sentinel-2-l2a\"\n",
    "\n",
    "bands = [\"blue\", \"green\", \"red\"]\n",
    "\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bands=bands,\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c5594",
   "metadata": {},
   "source": [
    "Now to query the data, we specify the bands we want to return, plus an (optional) save filename.  The `get_data()` function will query the data from the data source and return an xarray object containing all the fetched data with dimensions (time, band, y, x). All dates are stacked along the time dimension, and all bands are stacked along the band dimension.\n",
    "\n",
    "Optionally, if `save_file=` is provided as an argument to `get_data()`, individual GeoTIFF files will be saved for each date with the naming pattern: {save_file}_{date}.tif (e.g., 'output_2025-01-01.tif', 'output_2025-01-02.tif'). Each file contains all requested bands for that specific date.\n",
    "\n",
    "If the bands are not found for the collection chosen, it will try to match the alt names stored in the internal collections catalogue, otherwise it will fail and tell you the available bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6516110",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filestem = f\"./tmp_download/{data_connector}_{collection_name}\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=f\"{save_filestem}.tif\",\n",
    ")\n",
    "\n",
    "dai = scale_data_xarray(da, list(np.ones(len(bands))))\n",
    "dai = impute_nans_xarray(dai)\n",
    "save_data_array_to_file(dai, save_file=f\"{save_filestem}.tif\", imputed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c425de",
   "metadata": {},
   "source": [
    "### Sentinel-2-l2a from Sentinel Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73523a72",
   "metadata": {},
   "source": [
    "Before connecting to the Sentinel hub data connector, ensure credentials have been added to your local environment. The easiest way to do this is to add them to your `.env`. Login to [planet.com](https://www.planet.com) to generate a Oauth client ID and client secret, then add them to the `.env` file:\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "SH_CLIENT_ID=<your_token_here>\n",
    "SH_CLIENT_SECRET=<your_token_here>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connector = \"sentinelhub\"\n",
    "dc = DataConnector(connector_type=data_connector)\n",
    "dc.connector.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"s2_l2a\"\n",
    "bands = [\"B04\", \"B03\", \"B02\"]\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filestem = f\"./tmp_download/{data_connector}_{collection_name}\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=f\"{save_filestem}.tif\",\n",
    ")\n",
    "dai = scale_data_xarray(da, list(np.ones(len(bands))))\n",
    "dai = impute_nans_xarray(dai)\n",
    "save_data_array_to_file(dai, save_file=f\"{save_filestem}.tif\", imputed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a8b23",
   "metadata": {},
   "source": [
    "### Sentinel-1_grd from Sentinel Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"s1_grd\"\n",
    "\n",
    "bands = [\"VV\", \"VH\"]\n",
    "\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = unique_dates[0]\n",
    "save_filestem = f\"./tmp_download/{data_connector}_{collection_name}\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=date,\n",
    "    date_end=date,\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=f\"{save_filestem}.tif\",\n",
    ")\n",
    "\n",
    "dai = scale_data_xarray(da, list(np.ones(len(bands))))\n",
    "dai = impute_nans_xarray(dai)\n",
    "save_data_array_to_file(dai, save_file=f\"{save_filestem}.tif\", imputed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523eac1",
   "metadata": {},
   "source": [
    "### HLS-L30 from NASA Earthdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70cdb9",
   "metadata": {},
   "source": [
    "Before connecting to the NASA Earth data connector, ensure credentials have been added to your local environment. The easiest way to do this is to add them to your `.env`. Login to [urs.earthdata.nasa.gov](https://urs.earthdata.nasa.gov/) to generate a token, then add it to the `.env` file:\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "NASA_EARTH_BEARER_TOKEN=<your_token_here>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connector = \"nasa_earthdata\"\n",
    "dc = DataConnector(connector_type=data_connector)\n",
    "dc.connector.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cdd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"HLSL30_2.0\"\n",
    "\n",
    "bands = [\"B04\", \"B03\", \"B02\"]\n",
    "\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb40aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = unique_dates[0]\n",
    "save_filestem = f\"./tmp_download/{data_connector}_{collection_name}\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=\"2024-01-01\",\n",
    "    date_end=\"2024-01-31\",\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=f\"{save_filestem}.tif\",\n",
    ")\n",
    "\n",
    "dai = scale_data_xarray(da, list(np.ones(len(bands))))\n",
    "dai = impute_nans_xarray(dai)\n",
    "save_data_array_to_file(dai, save_file=f\"{save_filestem}.tif\", imputed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cbfa6",
   "metadata": {},
   "source": [
    "### Sentinel-5p-l3grd-ch4-wfmd from IBM Research STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb651b",
   "metadata": {},
   "source": [
    "Before connecting to the IBM Research STAC data connector, ensure credentials have been added to your local environment. The easiest way to do this is to add them to your `.env`.\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "APPID_ISSUER=<issuer>\n",
    "APPID_USERNAME=<user-email>\n",
    "APPID_PASSWORD=<user-password>\n",
    "CLIENT_ID=<client-id>\n",
    "CLIENT_SECRET=<client-secret>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connector = \"IBMResearchSTAC\"\n",
    "dc = DataConnector(connector_type=data_connector)\n",
    "dc.connector.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6aa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"sentinel-5p-l3grd-ch4-wfmd\"\n",
    "date_start = \"2024-01-19\"\n",
    "date_end = \"2024-01-21\"\n",
    "bands = [\"CH4_column_volume_mixing_ratio\"]\n",
    "bbox = [-102.3, 31.5, -101.7, 32.1]\n",
    "\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    bands=bands,\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"./tmp_download/{data_connector}_{collection_name}.nc\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=file_path,\n",
    ")\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ff5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(file_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = list(ds)[0]\n",
    "ds[variable].isel(bands=0, time=2).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0697ab4-b771-4835-b7e2-7362e20439c2",
   "metadata": {},
   "source": [
    "### Example for forecast temperature from The Weather Company\n",
    "Before connecting to the The Weather Company data connector, ensure credentials have been added to your local environment. The easiest way to do this is to add them to your .env. \n",
    "\n",
    "```\n",
    "# .env\n",
    "THE_WEATHER_COMPANY_API_KEY=<your_api_key_here>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845d8b6-6090-4cb5-9aaa-216be041f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connector = \"TheWeatherCompany\"\n",
    "dc = DataConnector(connector_type=data_connector)\n",
    "dc.connector.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1dc176-9ef8-4114-8436-14b6d4510a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"weathercompany-daily-forecast\"\n",
    "start_timestamp = pd.Timestamp.today().date()\n",
    "date_start = start_timestamp.isoformat()\n",
    "end_timestamp = start_timestamp + pd.Timedelta(15, unit=\"D\")\n",
    "date_end = end_timestamp.isoformat()\n",
    "bands = [\"temperatureMax\"]\n",
    "bbox = (-102.3, 31.5, -101.7, 32.1)\n",
    "\n",
    "unique_dates, results = dc.connector.find_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    bands=bands,\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66307fed-d983-4b87-83c7-c757cb6c4874",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\".\") / \"tmp_download\"\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "save_filestem = f\"./tmp_download/{data_connector}_{collection_name}\"\n",
    "\n",
    "da = dc.connector.get_data(\n",
    "    data_collection_name=collection_name,\n",
    "    date_start=date_start,\n",
    "    date_end=date_end,\n",
    "    bbox=bbox,\n",
    "    bands=bands,\n",
    "    save_file=f\"{save_filestem}.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2983869-ee6e-4a59-8cb8-918d7f57a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in data_dir.rglob(\"*.nc\"):\n",
    "    if file_path.is_file():\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530a540-d19f-456c-961e-b96418df1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"tmp_download/TheWeatherCompany_weathercompany-daily-forecast.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2ade4-c9ac-40be-aa65-2169b16f33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"__xarray_dataarray_variable__\"].isel(bands=0, time=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c44df7-de45-4925-841e-eaa3ce1d05a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
