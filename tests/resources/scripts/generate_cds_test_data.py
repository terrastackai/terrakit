# © Copyright IBM Corporation 2026
# SPDX-License-Identifier: Apache-2.0


#!/usr/bin/env python3
"""
Generate dummy CDS test data for mocking CDS API responses.

This script creates a zip file containing NetCDF files that simulate
CDS API responses for ERA5 daily statistics data.

The generated zip file will be saved to tests/resources/climate_data_store/
for use by the mock_cds_client fixture.

Usage:
    python tests/resources/scripts/generate_cds_test_data.py
"""

import numpy as np
import xarray as xr
import zipfile
from pathlib import Path
from datetime import datetime

# Output configuration
OUTPUT_DIR = Path("tests/resources/climate_data_store")
OUTPUT_ZIP_NAME = "era5_daily_statistics_test_data.zip"
TEMP_DIR = OUTPUT_DIR / "temp_netcdf"

# Data configuration matching the mock_cds_client comment
VARIABLES = [
    "10m_u_component_of_wind",
    "10m_v_component_of_wind",
    "2m_temperature",
    "total_precipitation",
    "10m_wind_gust_since_previous_post_processing",
]

# Spatial configuration (small test area for manageable file size)
# Using a small region instead of global to keep file size reasonable
LAT_MIN, LAT_MAX = 50.0, 52.0
LON_MIN, LON_MAX = -2.0, 0.0
LAT_RESOLUTION = 0.25  # 0.25 degree resolution
LON_RESOLUTION = 0.25

# Temporal configuration
DATES = ["2025-01-01", "2025-01-02"]  # Two days as per mock comment
TIME_ZONE = "utc+00:00"

# Variable metadata (units and typical value ranges)
VARIABLE_METADATA = {
    "10m_u_component_of_wind": {
        "units": "m s**-1",
        "long_name": "10 metre U wind component",
        "standard_name": "eastward_wind",
        "mean": 0.0,
        "std": 5.0,
    },
    "10m_v_component_of_wind": {
        "units": "m s**-1",
        "long_name": "10 metre V wind component",
        "standard_name": "northward_wind",
        "mean": 0.0,
        "std": 5.0,
    },
    "2m_temperature": {
        "units": "K",
        "long_name": "2 metre temperature",
        "standard_name": "air_temperature",
        "mean": 288.0,  # ~15°C
        "std": 15.0,
    },
    "total_precipitation": {
        "units": "m",
        "long_name": "Total precipitation",
        "standard_name": "precipitation_amount",
        "mean": 0.002,  # 2mm
        "std": 0.005,
    },
    "10m_wind_gust_since_previous_post_processing": {
        "units": "m s**-1",
        "long_name": "10 metre wind gust since previous post-processing",
        "mean": 8.0,
        "std": 4.0,
    },
}


def create_netcdf_for_variable(variable_name: str, dates: list, output_dir: Path):
    """
    Create a NetCDF file for a single variable with realistic dummy data.

    Args:
        variable_name: Name of the variable (e.g., '2m_temperature')
        dates: List of date strings in 'YYYY-MM-DD' format
        output_dir: Directory to save the NetCDF file
    """
    print(f"Creating NetCDF for {variable_name}...")

    # Create coordinate arrays
    lats = np.arange(LAT_MIN, LAT_MAX + LAT_RESOLUTION, LAT_RESOLUTION)
    lons = np.arange(LON_MIN, LON_MAX + LON_RESOLUTION, LON_RESOLUTION)
    times = [datetime.strptime(d, "%Y-%m-%d") for d in dates]

    # Get variable metadata
    metadata = VARIABLE_METADATA[variable_name]

    # Generate realistic dummy data
    # Shape: (time, lat, lon)
    shape = (len(times), len(lats), len(lons))

    # Create spatially and temporally varying data
    np.random.seed(42)  # For reproducibility

    # Base random data
    data = np.random.normal(metadata["mean"], metadata["std"], shape)

    # Add spatial patterns (latitude-dependent for temperature-like variables)
    if "temperature" in variable_name.lower():
        # Temperature decreases with latitude
        lat_effect = np.cos(np.deg2rad(lats)) * 20  # ±20K variation
        data += lat_effect[np.newaxis, :, np.newaxis]

    # Ensure non-negative values for precipitation
    if "precipitation" in variable_name.lower():
        data = np.abs(data)

    # Create xarray Dataset
    ds = xr.Dataset(
        {
            variable_name: (
                ["time", "latitude", "longitude"],
                data.astype(np.float32),
                {
                    "units": metadata["units"],
                    "long_name": metadata["long_name"],
                    "standard_name": metadata.get("standard_name", variable_name),
                },
            )
        },
        coords={
            "time": times,
            "latitude": lats,
            "longitude": lons,
        },
    )

    # Add global attributes
    ds.attrs = {
        "Conventions": "CF-1.6",
        "history": f"Generated by generate_cds_test_data.py on {datetime.now().isoformat()}",
        "source": "Dummy test data for CDS API mocking",
        "institution": "IBM Research",
    }

    # Add coordinate attributes
    ds["time"].attrs = {
        "standard_name": "time",
        "long_name": "time",
    }
    ds["latitude"].attrs = {
        "units": "degrees_north",
        "standard_name": "latitude",
        "long_name": "latitude",
    }
    ds["longitude"].attrs = {
        "units": "degrees_east",
        "standard_name": "longitude",
        "long_name": "longitude",
    }

    # Save to NetCDF
    output_file = output_dir / f"{variable_name}.nc"
    ds.to_netcdf(output_file, format="NETCDF4", engine="netcdf4")
    print(f"  Saved: {output_file}")

    return output_file


def create_cds_test_zip():
    """
    Create a zip file containing NetCDF files for all variables.

    This mimics the structure of a CDS API response where each variable
    is in a separate NetCDF file within a zip archive.
    """
    print("=" * 70)
    print("Generating CDS Test Data")
    print("=" * 70)

    # Create output and temporary directories
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    # Create NetCDF files for each variable
    netcdf_files = []
    for variable in VARIABLES:
        nc_file = create_netcdf_for_variable(variable, DATES, TEMP_DIR)
        netcdf_files.append(nc_file)

    # Create zip file
    output_zip = OUTPUT_DIR / OUTPUT_ZIP_NAME
    print(f"\nCreating zip file: {output_zip}")
    with zipfile.ZipFile(output_zip, "w", zipfile.ZIP_DEFLATED) as zipf:
        for nc_file in netcdf_files:
            zipf.write(nc_file, nc_file.name)
            print(f"  Added: {nc_file.name}")

    # Clean up temporary directory
    print(f"\nCleaning up temporary directory: {TEMP_DIR}")
    import shutil

    shutil.rmtree(TEMP_DIR)

    # Print summary
    print("\n" + "=" * 70)
    print("SUCCESS!")
    print("=" * 70)
    print(f"Created: {output_zip}")
    print(f"Variables: {len(VARIABLES)}")
    for var in VARIABLES:
        print(f"  - {var}")
    print(f"Dates: {len(DATES)} ({DATES[0]} to {DATES[-1]})")
    print(f"Spatial extent: {LAT_MIN}°N to {LAT_MAX}°N, {LON_MIN}°E to {LON_MAX}°E")
    print(f"Resolution: {LAT_RESOLUTION}° × {LON_RESOLUTION}°")

    # Get file size
    file_size = output_zip.stat().st_size / (1024 * 1024)  # MB
    print(f"File size: {file_size:.2f} MB")
    print("\nThis file can be used by the mock_cds_client fixture for testing.")
    print("=" * 70)


if __name__ == "__main__":
    create_cds_test_zip()

# Made with Bob
